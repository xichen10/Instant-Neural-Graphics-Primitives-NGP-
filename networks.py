import torch
from torch import nn
import tinycudann as tcnn
import vren
from utils.custom_utils import TruncExp
import numpy as np
from einops import rearrange, repeat, reduce
from utils.custom_utils import VolumeRenderer_REN
from utils.render_utils import NEAR_DISTANCE


class NGPNetwork(nn.Module):

    def __init__(self, scale, dataset_name):
        """
        ÂàùÂßãÂåñÊ®°Âûã
        :param scale:  Âú∫ÊôØÊØî‰æã
        """
        super().__init__()
        # Âú∫ÊôØÊØî‰æã
        self.scale = scale
        # Êï∞ÊçÆÁ±ªÂûã
        self.dataset_name = dataset_name
        # Âú∫ÊôØ‰∏≠ÂøÉ
        self.register_buffer('center', torch.zeros(1, 3))
        # xyzËΩ¥ÊúÄÂ∞èÂÄº
        self.register_buffer('xyz_min', -torch.ones(1, 3) * scale)
        # xyzËΩ¥ÊúÄÂ§ßÂÄº
        self.register_buffer('xyz_max', torch.ones(1, 3) * scale)
        # ‰ΩìÁ¥†Á©∫Èó¥‰∏ÄÂçäÂ§ßÂ∞è
        self.register_buffer('half_size', (self.xyz_max - self.xyz_min) / 2)
        # Ê∏≤ÊüìÊñπÁ®ã
        self.VolumeRenderer_REN = VolumeRenderer_REN()

        # ÁΩëÊ†ºËæπÊ°ÜÂ§ßÂ∞è [-2^(k-1), 2^(k-1)]^3 for k in [0, C-1]
        # K = 1 ÈÄÇÁî®‰∫é synthetic NeRFÔºåÂØπ‰∫éÂ§ßÂú∫ÊôØÔºåK [1,5]
        self.cascades = max(1 + int(np.ceil(np.log2(2 * scale))), 1)  # max (log2*0.5 Âêë‰∏äÂèñÊï¥Ôºå1)
        # ÁΩëÊ†ºÂ§ßÂ∞è
        self.grid_size = 128
        # ÁΩëÊ†ºÂùó 128*128*128 / 8  [262144]
        self.register_buffer('density_bitfield',
                             torch.zeros(self.cascades * self.grid_size ** 3 // 8, dtype=torch.uint8))
        # constants
        # L ÁâπÂÆöÂàÜËæ®Áéá‰ΩìÁ¥†ÂØπÂ∫îÁöÑÁºñÁ†ÅÂ±Ç
        # T ÊØè‰∏ÄÂ±ÇÂìàÂ∏åË°®Â§ßÂ∞è
        # N_min Á≤óÂàÜËæ®Áéá 16
        # N_max ÁªÜÂàÜËæ®Áéá 2048*scale
        # F ÊØè‰∏™Êù°ÁõÆÁöÑÁâπÂæÅÁª¥Â∫¶Êï∞
        L = 16;
        F = 2;
        log2_T = 19;
        N_min = 16
        b = np.exp(np.log(2048 * scale / N_min) / (L - 1))  # e^log(N_max/N_min)/(L-1)
        print(f'GridEncoding: Nmin={N_min} b={b:.5f} F={F} T=2^{log2_T} L={L}')
        # ËßÜÂõæÊñπÂêëÊäïÂΩ±Âà∞ÁêÉË∞êÂü∫ÁöÑÂâç16‰∏™Á≥ªÊï∞(Âç≥4Èò∂)‰∏ä
        self.dir_encoder = \
            tcnn.Encoding(
                n_input_dims=3,
                encoding_config={
                    "otype": "SphericalHarmonics",  # ÁêÉÈù¢Ë∞êÊ≥¢ ÁêÉÂáΩÊï∞
                    "degree": 4,  # Èò∂Êï∞
                },  # ‰ΩçÁΩÆÁºñÁ†Å 4Èò∂ÁêÉÂáΩÊï∞
            )
        # ÂØÜÂ∫¶MLP  ËæìÂÖ•ÂìàÂ∏åÁºñÁ†Å‰ΩçÁΩÆy = enc(x;ùúÉ)  ËæìÂá∫16‰ΩçÂØπÊï∞Á©∫Èó¥ÂØÜÂ∫¶
        self.xyz_encoder = \
            tcnn.NetworkWithInputEncoding(
                n_input_dims=3, n_output_dims=16,  # ËæìÂÖ•Áª¥Â∫¶ 3 ËæìÂá∫Áª¥Â∫¶ 16ÔºàÂ§öÂàÜËæ®Áéá Á∫øÊÄßÊèíÂÄº ‰∏≤ËÅîÔºâ
                encoding_config={
                    "otype": "Grid",
                    "type": "Hash",
                    "n_levels": L,
                    "n_features_per_level": F,
                    "log2_hashmap_size": log2_T,
                    "base_resolution": N_min,
                    "per_level_scale": b,
                    "interpolation": "Linear"
                },  # ‰ΩçÁΩÆÁºñÁ†ÅÔºöÂ§öÂàÜËæ®Áéá ‰ΩìÁ¥†ÁΩëÊ†º hashË°®Â≠òÂÇ®
                network_config={
                    "otype": "FullyFusedMLP",
                    "activation": "ReLU",
                    "output_activation": "None",
                    "n_neurons": 64,
                    "n_hidden_layers": 1,
                }  # Â∞èMLPÁΩëÁªú
            )
        if "rffr" == self.dataset_name:
            self.t_rgb = \
                tcnn.Network(
                    n_input_dims=32, n_output_dims=3,
                    network_config={
                        "otype": "FullyFusedMLP",
                        "activation": "ReLU",
                        "output_activation": "Sigmoid",
                        "n_neurons": 64,
                        "n_hidden_layers": 2,
                    }
                )
            self.r_rgb = \
                tcnn.Network(
                    n_input_dims=16, n_output_dims=4,
                    network_config={
                        "otype": "FullyFusedMLP",
                        "activation": "ReLU",
                        "output_activation": "Sigmoid",
                        "n_neurons": 64,
                        "n_hidden_layers": 1,
                    }
                )
        else:
            self.rgb_net = \
                tcnn.Network(
                    n_input_dims=32, n_output_dims=3,
                    network_config={
                        "otype": "FullyFusedMLP",
                        "activation": "ReLU",
                        "output_activation": "Sigmoid",
                        "n_neurons": 64,
                        "n_hidden_layers": 2,
                    }
                )

    def density(self, x, return_feat=False):
        """
        Ëé∑ÂèñÈÄèÊòéÂ∫¶
        :param x: (N, 3) xyz in [-scale, scale]
        :param return_feat: ÊòØÂê¶ËøîÂõû‰∏≠Èó¥ÁâπÂæÅ
        :return:
            sigmas: (N)
        """
        x = (x - self.xyz_min) / (self.xyz_max - self.xyz_min)  # ÂΩí‰∏ÄÂåñ
        h = self.xyz_encoder(x)  # Ëé∑Âèñ32‰Ωç‰ΩçÁΩÆÁºñÁ†Å
        sigmas = TruncExp.apply(h[:, 0])
        if "rffr" == self.dataset_name:
            sigmas = TruncExp.apply(h[:, 0])
            t_beta = TruncExp.apply(h[:, 1])
            if return_feat:
                return sigmas, h, t_beta
            else:
                return sigmas
        else:
            if return_feat: return sigmas, h
            return sigmas

    def forward(self, x, d):
        """

        :param x: (N, 3) xyz in [-scale, scale]
        :param d: (N, 3) directions
        :return:
            sigmas: (N)
            rgb: (N, 3)
        """
        if "rffr" == self.dataset_name:
            # t
            t_sigmas, h, t_beta = self.density(x, return_feat=True)
            d = d / torch.norm(d, dim=1, keepdim=True)
            d = self.dir_encoder((d + 1) / 2)
            t_rgb = self.t_rgb(torch.cat([d, h], 1))

            # r
            r_rgb_sigmas = self.r_rgb(h)
            r_sigmas = TruncExp.apply(r_rgb_sigmas[:, -1:])
            r_rgb = TruncExp.apply(r_rgb_sigmas[:, :-1])

            return t_sigmas, t_rgb, t_beta, rearrange(r_sigmas, "n 1->n"), r_rgb
        else:
            sigmas, h = self.density(x, return_feat=True)
            d = d / torch.norm(d, dim=1, keepdim=True)
            d = self.dir_encoder((d + 1) / 2)
            rgb = self.rgb_net(torch.cat([d, h], 1))
            return sigmas, rgb

    @torch.no_grad()
    def get_all_cells(self):
        """
        ‰ªéÂØÜÂ∫¶ÁΩëÊ†º‰∏≠Ëé∑ÂèñÊâÄÊúâÂçïÂÖÉÊ†º
        :return:
            cells ÂçïÂÖÉÊ†º
        """
        indices = vren.morton3D(self.grid_coords).long()  # grid_coords [2097152,3] ÁΩëÊ†ºÂùêÊ†áÔºà[1,128,128,128,3]Ôºâ
        cells = [(indices, self.grid_coords)] * self.cascades
        return cells

    @torch.no_grad()
    def sample_uniform_and_occupied_cells(self, M, density_threshold):
        """
        ÂØπMÂùáÂåÄÂçïÂÖÉÊ†ºÂíåÂ∑≤Âç†Áî®ÂçïÂÖÉÊ†ºËøõË°åÈááÊ†∑
        :param M:
        :param density_threshold: ÂØÜÂ∫¶ÈòàÂÄº
        :return:
            cells ÂçïÂÖÉÊ†º
        """
        cells = []
        for c in range(self.cascades):
            # uniform cells
            coords1 = torch.randint(self.grid_size, (M, 3), dtype=torch.int32,
                                    device=self.density_grid.device)
            indices1 = vren.morton3D(coords1).long()
            # occupied cells
            indices2 = torch.nonzero(self.density_grid[c] > density_threshold)[:, 0]
            if len(indices2) > 0:
                rand_idx = torch.randint(len(indices2), (M,),
                                         device=self.density_grid.device)
                indices2 = indices2[rand_idx]
            coords2 = vren.morton3D_invert(indices2.int())
            # concatenate
            cells += [(torch.cat([indices1, indices2]), torch.cat([coords1, coords2]))]

        return cells

    @torch.no_grad()
    def mark_invisible_cells(self, K, poses, img_wh, chunk=64 ** 3):
        """
        ÂØÜÈõÜÁΩëÊ†ºÂàùÂßãÂåñÔºåÁî®ÂØÜÂ∫¶-1Ê†áËÆ∞Êú™Ë¢´ÊëÑÂÉèÊú∫Ë¶ÜÁõñÁöÑÂçïÂÖÉÊ†ºÔºåËÆ≠ÁªÉÂºÄÂßãÂâçÂè™ÊâßË°å‰∏ÄÊ¨°
        :param K:  (3, 3) camera intrinsics
        :param poses:  (N, 3, 4) camera to world poses
        :param img_wh:  image width and height
        :param chunk: the chunk size to split the cells (to avoid OOM)
        :return:
        """
        N_cams = poses.shape[0]  # 100
        self.count_grid = torch.zeros_like(self.density_grid)  # density_grid [1, 128*128*128]
        w2c_R = poses[:, :3, :3].mT  # batch transpose w2c_R (N_cams, 3, 3) poses [100,3,4]
        w2c_T = -w2c_R @ poses[:, :3, 3:]  # (N_cams, 3, 1)
        cells = self.get_all_cells()  # ‰ªéÂØÜÂ∫¶ÁΩëÊ†º‰∏≠Ëé∑ÂèñÊâÄÊúâÂçïÂÖÉÊ†º
        for c in range(self.cascades):
            indices, coords = cells[c]
            for i in range(0, len(indices), chunk):
                xyzs = coords[i:i + chunk] / (self.grid_size - 1) * 2 - 1
                s = min(2 ** (c - 1), self.scale)
                half_grid_size = s / self.grid_size
                xyzs_w = (xyzs * (s - half_grid_size)).T  # (3, chunk)
                xyzs_c = w2c_R @ xyzs_w + w2c_T  # (N_cams, 3, chunk)
                uvd = K @ xyzs_c  # (N_cams, 3, chunk)
                uv = uvd[:, :2] / uvd[:, 2:]  # (N_cams, 2, chunk)
                in_image = (uvd[:, 2] >= 0) & \
                           (uv[:, 0] >= 0) & (uv[:, 0] < img_wh[0]) & \
                           (uv[:, 1] >= 0) & (uv[:, 1] < img_wh[1])
                covered_by_cam = (uvd[:, 2] >= NEAR_DISTANCE) & in_image  # (N_cams, chunk)
                # if the cell is visible by at least one camera
                self.count_grid[c, indices[i:i + chunk]] = \
                    count = covered_by_cam.sum(0) / N_cams

                too_near_to_cam = (uvd[:, 2] < NEAR_DISTANCE) & in_image  # (N, chunk)
                # if the cell is too close (in front) to any camera
                too_near_to_any_cam = too_near_to_cam.any(0)
                # a valid cell should be visible by at least one camera and not too close to any camera
                valid_mask = (count > 0) & (~too_near_to_any_cam)
                self.density_grid[c, indices[i:i + chunk]] = \
                    torch.where(valid_mask, 0., -1.)

    @torch.no_grad()
    def update_density_grid(self, density_threshold, warmup=False, decay=0.95, erode=False):
        """
        Êõ¥Êñ∞ÂçïÂÖÉÊ†º
        :param density_threshold: ÂØÜÂ∫¶ÈòàÂÄº
        :param warmup: È¢ÑËÆ≠ÁªÉ
        :param decay:  ÂØÜÂ∫¶Ë°∞Âèò
        :return:
        """
        density_grid_tmp = torch.zeros_like(self.density_grid)
        if warmup:  # during the first steps
            cells = self.get_all_cells()
        else:
            cells = self.sample_uniform_and_occupied_cells(self.grid_size ** 3 // 4,
                                                           density_threshold)
        # infer sigmas
        for c in range(self.cascades):
            indices, coords = cells[c]
            s = min(2 ** (c - 1), self.scale)
            half_grid_size = s / self.grid_size
            xyzs_w = (coords / (self.grid_size - 1) * 2 - 1) * (s - half_grid_size)
            # pick random position in the cell by adding noise in [-hgs, hgs]
            xyzs_w += (torch.rand_like(xyzs_w) * 2 - 1) * half_grid_size
            density_grid_tmp[c, indices] = self.density(xyzs_w)

        if erode:
            # My own logic. decay more the cells that are visible to few cameras
            decay = torch.clamp(decay ** (1 / self.count_grid), 0.1, 0.95)

        self.density_grid = \
            torch.where(self.density_grid < 0,
                        self.density_grid,
                        torch.maximum(self.density_grid * decay, density_grid_tmp))
        mean_density = self.density_grid[self.density_grid > 0].mean().item()
        vren.packbits(self.density_grid, min(mean_density, density_threshold),
                      self.density_bitfield)
